{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_detector.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPk5HSWvxsWGttZkEqS4Kfn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Azitt/ML_pytorch_Audioprocessing/blob/main/ML_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZGMX8tK37um6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "device='cpu'\n",
        "#device='cuda'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LinNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinNet, self).__init__()\n",
        "        # Define the model.\n",
        "        self.layer1 = nn.Sequential(nn.Linear(in_features=2, out_features=2, bias=True))\n",
        "        # Generate a fully connected linear neural network model, 1 layer, bias, linear activation function\n",
        "        # returns: Trainable object\n",
        "        #self.act = nn.LeakyReLU() #non-linear activation function\n",
        "        #self.act = nn.ReLU() #non-linear activation function\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        #out = self.act(out) #comment out if not desired\n",
        "        return out"
      ],
      "metadata": {
        "id": "FpG8F4_78DQ9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data_preparation"
      ],
      "metadata": {
        "id": "tTZc--5m8Qba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#input tensor, type torch tensor:\n",
        "#Indices: batch, sample, features or signal dimension. Here: 1 batch, 3 samples, signal dimension 2:\n",
        "\n",
        "#Training set:\n",
        "X=torch.tensor([[1., 2.], [2., 1.],[1., 1.]]).view(1,3,2) #adding the first dimension for the batch\n",
        "print(\"X.shape\", X.shape)\n",
        "\n",
        "#Target:\n",
        "Y=torch.tensor([[1., 0.], [0., 1.],[0., 0.]]).view(1,3,2)\n",
        "print(\"Y.shape\", Y.shape)\n",
        "\n",
        "#Validation set, to test generalization:\n",
        "Xval=torch.tensor([[0.5, 1.0], [1., 0.5],[0.5, 0.5]]).view(1,3,2)\n",
        "#Validation Target:\n",
        "Yval=torch.tensor([[1., 0.], [0., 1.],[0., 0.]]).view(1,3,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNG7TZr98Tip",
        "outputId": "2ef9e5e5-99b0-4de8-ca29-8b9bf846be1e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape torch.Size([1, 3, 2])\n",
            "Y.shape torch.Size([1, 3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create network object:\n",
        "model = LinNet().to(device)\n",
        "loss_fn = nn.MSELoss()\n",
        "print(\"Define loss function:\", loss_fn)\n",
        "#learning_rate = 1e-4\n",
        "#optimizer = torch.optim.Adam(model.parameters())\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
        "print(\"Define optimizer:\", optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3KJ3fPW8s87",
        "outputId": "33776a24-8f6b-482e-c7ea-6eaa6fb483ad"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Define loss function: MSELoss()\n",
            "Define optimizer: SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.1\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10000):\n",
        "    Ypred=model(X) #the model produces prediction output\n",
        "    loss=loss_fn(Ypred, Y) #prediction and target compared by loss\n",
        "    if epoch%1000==0:\n",
        "        print(epoch, loss.item()) #print current loss value\n",
        "    optimizer.zero_grad() #optimizer sets previous gradients to zero\n",
        "    loss.backward() #optimizer computes new gradients\n",
        "    optimizer.step() #optimizer updates weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W5YkwgZ80jJ",
        "outputId": "198e5e14-90d8-4a43-8916-b4872d16d73b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.9826375246047974\n",
            "1000 0.0002927322348114103\n",
            "2000 2.4277860575239174e-06\n",
            "3000 2.016355260536784e-08\n",
            "4000 1.6898364652018216e-10\n",
            "5000 4.4426684553400264e-12\n",
            "6000 4.4426684553400264e-12\n",
            "7000 4.4426684553400264e-12\n",
            "8000 4.4426684553400264e-12\n",
            "9000 4.4426684553400264e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ypred=model(X) # Make Predictions based on the obtained weights\n",
        "loss=loss_fn(Ypred, Y)\n",
        "print(\"Loss on trainig set:\", loss)\n",
        "Yvalpred=model(Xval) # Make Predictions based on the obtained weights\n",
        "loss=loss_fn(Yvalpred, Yval)\n",
        "print(\"Loss on validation set:\", loss)\n",
        "weights = model.state_dict() #read obtained weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaaQiyMN9KqZ",
        "outputId": "0f64afe9-9d55-41f9-99ed-50e338ff4050"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on trainig set: tensor(4.4427e-12, grad_fn=<MseLossBackward0>)\n",
            "Loss on validation set: tensor(0.5000, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The loss values: Only **4.6493e-12** on the **training se**t, but **0.5000** on the **validation** set Hence we have a **bad generalization**."
      ],
      "metadata": {
        "id": "FBBt6Vwb9_qc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#*We add activation function and train the model and check the output*****"
      ],
      "metadata": {
        "id": "Job9bPZ1Ay2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinNet2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinNet2, self).__init__()\n",
        "        # Define the model.\n",
        "        self.layer1 = nn.Sequential(nn.Linear(in_features=2, out_features=2, bias=True))\n",
        "        # Generate a fully connected linear neural network model, 1 layer, bias, linear activation function\n",
        "        # returns: Trainable object\n",
        "        self.act = nn.LeakyReLU() #non-linear activation function\n",
        "        #self.act = nn.ReLU() #non-linear activation function\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.act(out) #comment out if not desired\n",
        "        return out"
      ],
      "metadata": {
        "id": "a0crL1KL-QDS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create network object:\n",
        "model = LinNet2().to(device)\n",
        "loss_fn = nn.MSELoss()\n",
        "print(\"Define loss function:\", loss_fn)\n",
        "#learning_rate = 1e-4\n",
        "#optimizer = torch.optim.Adam(model.parameters())\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
        "print(\"Define optimizer:\", optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HniLGB9ZAtbB",
        "outputId": "11f01b64-875c-4c82-a7ca-a310bb7f007e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Define loss function: MSELoss()\n",
            "Define optimizer: SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.1\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10000):\n",
        "    Ypred=model(X) #the model produces prediction output\n",
        "    loss=loss_fn(Ypred, Y) #prediction and target compared by loss\n",
        "    if epoch%1000==0:\n",
        "        print(epoch, loss.item()) #print current loss value\n",
        "    optimizer.zero_grad() #optimizer sets previous gradients to zero\n",
        "    loss.backward() #optimizer computes new gradients\n",
        "    optimizer.step() #optimizer updates weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlh2T_aZCBeY",
        "outputId": "5cc1e571-d648-46ec-ea73-37491ac33184"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.3932311236858368\n",
            "1000 1.4584293239749968e-05\n",
            "2000 1.4528071005770471e-05\n",
            "3000 1.4480231584457215e-05\n",
            "4000 1.4432474017667118e-05\n",
            "5000 1.438479739590548e-05\n",
            "6000 1.4337198081193492e-05\n",
            "7000 1.4289677892520558e-05\n",
            "8000 1.4242238648876082e-05\n",
            "9000 1.4194876712281257e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ypred=model(X) # Make Predictions based on the obtained weights\n",
        "loss=loss_fn(Ypred, Y)\n",
        "print(\"Loss on trainig set:\", loss)\n",
        "Yvalpred=model(Xval) # Make Predictions based on the obtained weights\n",
        "loss=loss_fn(Yvalpred, Yval)\n",
        "print(\"Loss on validation set:\", loss)\n",
        "weights = model.state_dict() #read obtained weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKK7cfl9AwFX",
        "outputId": "e82fbad6-05f8-46bd-b579-08970b806419"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on trainig set: tensor(1.4148e-05, grad_fn=<MseLossBackward0>)\n",
            "Loss on validation set: tensor(0.1697, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The loss values: Only **1.4148e-05** on the **training set**, but **0.1697** on the **validation set** Hence we have a better generalization than first model."
      ],
      "metadata": {
        "id": "iZZi7IYrCV52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see the effect of vanishing gradients on the optimization, we uncomment the line with \"self.act=nn.ReLU()\".\n",
        "**This activation function has a constant \"0\" for negative values and hence a vanishing gradient for negative values.** "
      ],
      "metadata": {
        "id": "VDzpCqlkCv04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinNet3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinNet3, self).__init__()\n",
        "        # Define the model.\n",
        "        self.layer1 = nn.Sequential(nn.Linear(in_features=2, out_features=2, bias=True))\n",
        "        # Generate a fully connected linear neural network model, 1 layer, bias, linear activation function\n",
        "        # returns: Trainable object\n",
        "        #self.act = nn.LeakyReLU() #non-linear activation function\n",
        "        self.act = nn.ReLU() #non-linear activation function\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.act(out) #comment out if not desired\n",
        "        return out"
      ],
      "metadata": {
        "id": "JXkvaGdWClFl"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create network object:\n",
        "model = LinNet3().to(device)\n",
        "loss_fn = nn.MSELoss()\n",
        "print(\"Define loss function:\", loss_fn)\n",
        "#learning_rate = 1e-4\n",
        "#optimizer = torch.optim.Adam(model.parameters())\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
        "print(\"Define optimizer:\", optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33gXZF5YDroX",
        "outputId": "fc458262-01c6-4c75-ea29-62cd2d7a1c1a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Define loss function: MSELoss()\n",
            "Define optimizer: SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    lr: 0.1\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10000):\n",
        "    Ypred=model(X) #the model produces prediction output\n",
        "    loss=loss_fn(Ypred, Y) #prediction and target compared by loss\n",
        "    if epoch%1000==0:\n",
        "        print(epoch, loss.item()) #print current loss value\n",
        "    optimizer.zero_grad() #optimizer sets previous gradients to zero\n",
        "    loss.backward() #optimizer computes new gradients\n",
        "    optimizer.step() #optimizer updates weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vcl-1YaqDvs2",
        "outputId": "396fbaa7-f949-4bb1-ba99-5e83959a271a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.4259568750858307\n",
            "1000 0.3333333432674408\n",
            "2000 0.3333333432674408\n",
            "3000 0.3333333432674408\n",
            "4000 0.3333333432674408\n",
            "5000 0.3333333432674408\n",
            "6000 0.3333333432674408\n",
            "7000 0.3333333432674408\n",
            "8000 0.3333333432674408\n",
            "9000 0.3333333432674408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ypred=model(X) # Make Predictions based on the obtained weights\n",
        "loss=loss_fn(Ypred, Y)\n",
        "print(\"Loss on trainig set:\", loss)\n",
        "Yvalpred=model(Xval) # Make Predictions based on the obtained weights\n",
        "loss=loss_fn(Yvalpred, Yval)\n",
        "print(\"Loss on validation set:\", loss)\n",
        "weights = model.state_dict() #read obtained weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD_N2m0vD1kn",
        "outputId": "575df637-f3fb-4f4b-a299-d455de54501c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss on trainig set: tensor(0.3333, grad_fn=<MseLossBackward0>)\n",
            "Loss on validation set: tensor(0.3600, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **optimizer gets stuck at a loss value of 0.33** during training. This is cause by the vanishing gradient of the ReLU function in the negative input range."
      ],
      "metadata": {
        "id": "In5fXYQDEa5W"
      }
    }
  ]
}